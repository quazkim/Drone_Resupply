name: PDP Solver - Run Experiments

on:
  workflow_dispatch:
    inputs:
      population_size:
        description: 'Sá»‘ cÃ¡ thá»ƒ GA (Population Size)'
        required: true
        default: '50'
        type: string
      max_generations:
        description: 'Sá»‘ tháº¿ há»‡ tá»‘i Ä‘a (Max Generations)'
        required: true
        default: '100'
        type: string
      mutation_rate:
        description: 'Tá»· lá»‡ Ä‘á»™t biáº¿n (Mutation Rate, 0.0-1.0)'
        required: true
        default: '0.1'
        type: string
      ls_iterations:
        description: 'Sá»‘ vÃ²ng láº·p Local Search'
        required: true
        default: '100'
        type: string
      instance_file:
        description: 'File instance (e.g., U_50_1.0_Num_1_pd.txt)'
        required: true
        default: 'U_50_1.0_Num_1_pd.txt'
        type: string
      run_count:
        description: 'Sá»‘ láº§n cháº¡y (Ä‘á»ƒ láº¥y trung bÃ¬nh)'
        required: true
        default: '1'
        type: string

jobs:
  run-solver:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
    
    - name: Setup build environment
      run: |
        sudo apt-get update
        sudo apt-get install -y g++ make
    
    - name: Compile solver
      run: |
        g++ -O2 -std=c++17 -o pdp_solver \
          main_ga_tabu.cpp \
          pdp_reader.cpp \
          pdp_utils.cpp \
          pdp_ga.cpp \
          pdp_tabu.cpp \
          pdp_fitness.cpp \
          pdp_localsearch.cpp \
          pdp_init.cpp
        echo "âœ… Compilation successful!"
    
    - name: Update Local Search iterations
      run: |
        # Update LS iterations in main_ga_tabu.cpp
        sed -i "s/IntegratedLocalSearch ils(data, [0-9]*)/IntegratedLocalSearch ils(data, ${{ inputs.ls_iterations }})/g" main_ga_tabu.cpp
        
        # Recompile with updated LS iterations
        g++ -O2 -std=c++17 -o pdp_solver \
          main_ga_tabu.cpp \
          pdp_reader.cpp \
          pdp_utils.cpp \
          pdp_ga.cpp \
          pdp_tabu.cpp \
          pdp_fitness.cpp \
          pdp_localsearch.cpp \
          pdp_init.cpp
        echo "âœ… Recompiled with LS iterations = ${{ inputs.ls_iterations }}"
    
    - name: Run experiments
      run: |
        echo "=========================================="
        echo "  PDP SOLVER EXPERIMENT"
        echo "=========================================="
        echo "Instance: ${{ inputs.instance_file }}"
        echo "Population Size: ${{ inputs.population_size }}"
        echo "Max Generations: ${{ inputs.max_generations }}"
        echo "Mutation Rate: ${{ inputs.mutation_rate }}"
        echo "LS Iterations: ${{ inputs.ls_iterations }}"
        echo "Run Count: ${{ inputs.run_count }}"
        echo "=========================================="
        
        # Create results directory
        mkdir -p results
        
        # Initialize CSV file
        TIMESTAMP=$(date +%Y%m%d_%H%M%S)
        RESULT_FILE="results/experiment_${TIMESTAMP}.csv"
        
        echo "Run,Instance,PopSize,MaxGen,MutRate,LSIter,CostBeforeLS,CostAfterLS,Improvement,ImprovementPct,Feasible,ResupplyEvents,Runtime_sec" > $RESULT_FILE
        
        # Run experiments
        for run in $(seq 1 ${{ inputs.run_count }}); do
          echo ""
          echo ">>> Run $run / ${{ inputs.run_count }}"
          
          START_TIME=$(date +%s.%N)
          
          # Run solver and capture output
          OUTPUT=$(./pdp_solver \
            "${{ inputs.instance_file }}" \
            ${{ inputs.population_size }} \
            ${{ inputs.max_generations }} \
            ${{ inputs.mutation_rate }} \
            $run 2>&1)
          
          END_TIME=$(date +%s.%N)
          RUNTIME=$(echo "$END_TIME - $START_TIME" | bc)
          
          # Parse results from output
          COST_BEFORE=$(echo "$OUTPUT" | grep "Cost before Local Search:" | awk '{print $5}')
          COST_AFTER=$(echo "$OUTPUT" | grep "Cost after Local Search:" | awk '{print $5}')
          IMPROVEMENT=$(echo "$OUTPUT" | grep "Improvement by LS:" | awk '{print $4}')
          IMPROVEMENT_PCT=$(echo "$OUTPUT" | grep "Improvement by LS:" | grep -oP '\(\K[0-9.]+(?=%)')
          FEASIBLE=$(echo "$OUTPUT" | grep "Feasible:" | awk '{print $2}')
          RESUPPLY=$(echo "$OUTPUT" | grep "Resupply Events:" | awk '{print $3}')
          
          # Handle case where no improvement
          if [ -z "$IMPROVEMENT" ]; then
            IMPROVEMENT="0"
            IMPROVEMENT_PCT="0"
          fi
          
          # Write to CSV
          echo "$run,${{ inputs.instance_file }},${{ inputs.population_size }},${{ inputs.max_generations }},${{ inputs.mutation_rate }},${{ inputs.ls_iterations }},$COST_BEFORE,$COST_AFTER,$IMPROVEMENT,$IMPROVEMENT_PCT,$FEASIBLE,$RESUPPLY,$RUNTIME" >> $RESULT_FILE
          
          echo "  Cost: $COST_BEFORE -> $COST_AFTER (Improvement: $IMPROVEMENT_PCT%)"
          echo "  Runtime: ${RUNTIME}s"
        done
        
        echo ""
        echo "=========================================="
        echo "  RESULTS SAVED TO: $RESULT_FILE"
        echo "=========================================="
        cat $RESULT_FILE
        
        # Save result file path for artifact
        echo "RESULT_FILE=$RESULT_FILE" >> $GITHUB_ENV
    
    - name: Generate summary report
      run: |
        echo "# ðŸ“Š PDP Solver Experiment Results" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "## Configuration" >> $GITHUB_STEP_SUMMARY
        echo "| Parameter | Value |" >> $GITHUB_STEP_SUMMARY
        echo "|-----------|-------|" >> $GITHUB_STEP_SUMMARY
        echo "| Instance | \`${{ inputs.instance_file }}\` |" >> $GITHUB_STEP_SUMMARY
        echo "| Population Size | ${{ inputs.population_size }} |" >> $GITHUB_STEP_SUMMARY
        echo "| Max Generations | ${{ inputs.max_generations }} |" >> $GITHUB_STEP_SUMMARY
        echo "| Mutation Rate | ${{ inputs.mutation_rate }} |" >> $GITHUB_STEP_SUMMARY
        echo "| LS Iterations | ${{ inputs.ls_iterations }} |" >> $GITHUB_STEP_SUMMARY
        echo "| Run Count | ${{ inputs.run_count }} |" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "## Results" >> $GITHUB_STEP_SUMMARY
        echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
        cat $RESULT_FILE >> $GITHUB_STEP_SUMMARY
        echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
        
        # Calculate statistics if multiple runs
        if [ "${{ inputs.run_count }}" -gt 1 ]; then
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## Statistics" >> $GITHUB_STEP_SUMMARY
          
          # Calculate average cost
          AVG_COST=$(tail -n +2 $RESULT_FILE | awk -F',' '{sum+=$8; count++} END {printf "%.2f", sum/count}')
          MIN_COST=$(tail -n +2 $RESULT_FILE | awk -F',' 'NR==1{min=$8} $8<min{min=$8} END {print min}')
          MAX_COST=$(tail -n +2 $RESULT_FILE | awk -F',' 'NR==1{max=$8} $8>max{max=$8} END {print max}')
          AVG_RUNTIME=$(tail -n +2 $RESULT_FILE | awk -F',' '{sum+=$13; count++} END {printf "%.2f", sum/count}')
          
          echo "| Metric | Value |" >> $GITHUB_STEP_SUMMARY
          echo "|--------|-------|" >> $GITHUB_STEP_SUMMARY
          echo "| Average Cost | $AVG_COST |" >> $GITHUB_STEP_SUMMARY
          echo "| Min Cost | $MIN_COST |" >> $GITHUB_STEP_SUMMARY
          echo "| Max Cost | $MAX_COST |" >> $GITHUB_STEP_SUMMARY
          echo "| Average Runtime | ${AVG_RUNTIME}s |" >> $GITHUB_STEP_SUMMARY
        fi
    
    - name: Upload results artifact
      uses: actions/upload-artifact@v4
      with:
        name: experiment-results-${{ github.run_number }}
        path: results/
        retention-days: 30

  # Job to run multiple instances (batch experiment)
  batch-experiment:
    if: ${{ inputs.run_count > 1 }}
    needs: run-solver
    runs-on: ubuntu-latest
    steps:
    - name: Download results
      uses: actions/download-artifact@v4
      with:
        name: experiment-results-${{ github.run_number }}
        path: results/
    
    - name: Generate Excel report
      run: |
        # Install Python and pandas
        sudo apt-get install -y python3-pip
        pip3 install pandas openpyxl
        
        # Create Python script to generate Excel
        cat > generate_excel.py << 'EOF'
import pandas as pd
import glob
import os

# Find CSV files
csv_files = glob.glob('results/*.csv')
if not csv_files:
    print("No CSV files found")
    exit(1)

# Read and combine all CSVs
dfs = []
for f in csv_files:
    df = pd.read_csv(f)
    dfs.append(df)

combined = pd.concat(dfs, ignore_index=True)

# Generate Excel file
excel_file = 'results/experiment_results.xlsx'
with pd.ExcelWriter(excel_file, engine='openpyxl') as writer:
    # Raw data sheet
    combined.to_excel(writer, sheet_name='Raw Data', index=False)
    
    # Summary statistics
    summary = combined.groupby('Instance').agg({
        'CostAfterLS': ['mean', 'min', 'max', 'std'],
        'ImprovementPct': ['mean', 'max'],
        'Runtime_sec': ['mean', 'sum']
    }).round(2)
    summary.columns = ['_'.join(col) for col in summary.columns]
    summary.to_excel(writer, sheet_name='Summary')

print(f"Excel report generated: {excel_file}")
EOF
        
        python3 generate_excel.py
    
    - name: Upload Excel report
      uses: actions/upload-artifact@v4
      with:
        name: excel-report-${{ github.run_number }}
        path: results/experiment_results.xlsx
        retention-days: 30
